name: Notify on Scraper Failure

on:
  workflow_run:
    workflows: ["Wildlife Jobs Scraper"]
    types:
      - completed

jobs:
  notify-failure:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'failure' }}
    
    steps:
    - name: Create Issue on Failure
      uses: actions/github-script@v6
      with:
        script: |
          const title = `ðŸš¨ Wildlife Jobs Scraper Failed - ${new Date().toISOString().split('T')[0]}`;
          const body = `
          ## Scraper Failure Report
          
          **Workflow Run**: ${context.payload.workflow_run.html_url}
          **Run ID**: ${context.payload.workflow_run.id}
          **Trigger**: ${context.payload.workflow_run.event}
          **Time**: ${context.payload.workflow_run.created_at}
          
          ### Possible Causes
          - Website structure changes
          - ChromeDriver compatibility issues
          - Network connectivity problems
          - Rate limiting by target site
          
          ### Next Steps
          1. Check the [workflow logs](${context.payload.workflow_run.html_url}) for specific errors
          2. Test scraper locally with \`python wildlife_job_scraper.py\`
          3. Inspect website for layout changes at https://jobs.rwfm.tamu.edu/search/
          4. Update selectors if needed
          
          **Auto-generated by GitHub Actions**
          `;
          
          // Check if similar issue already exists
          const existingIssues = await github.rest.issues.listForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            state: 'open',
            labels: 'scraper-failure'
          });
          
          if (existingIssues.data.length === 0) {
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: body,
              labels: ['scraper-failure', 'bug', 'automated']
            });
          }